{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNPDUkjnMcfdGf2l/yDGRb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitgupta1998/Doodle_recogn_BEproject/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0ECv9kjDwO6",
        "colab_type": "code",
        "outputId": "7e6189e8-5d5c-4941-fd34-a64772ad769e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import cv2\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import test as test #file name, look how to import colab file\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4FWd6AX_rEt",
        "colab_type": "code",
        "outputId": "0e9f0eb2-1d42-4e86-93d4-743197d44da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CId4TMBERyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_data='/content/drive/My Drive/BE_project_dataset_and_code/data/'    \n",
        "def create_dic(dir_data):\n",
        "    dict={}\n",
        "    i=0\n",
        "    for file in sorted(os.listdir('/content/drive/My Drive/BE_project_dataset_and_code/data/')):\n",
        "        if file.endswith(\".npy\"):\n",
        "            str=file.split(\".\")\n",
        "            dict[i]=str[0]\n",
        "            i=i+1\n",
        "    return i,dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evd5k9cOEShs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cnn:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 128\n",
        "        self.dir_data='/content/drive/My Drive/BE_project_dataset_and_code/data/'\n",
        "        self.num_of_classes,self.dict =create_dic(self.dir_data)\n",
        "        self.image_size = 28\n",
        "        self.validate_data = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM62gAtbElCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVHN_net_v0(x_,num_of_classes):\n",
        "    with tf.variable_scope(\"CNN\"):\n",
        "        conv1 = tf.layers.conv2d(\n",
        "                                 inputs=x_,\n",
        "                                 filters=32,  # number of filters\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 padding=\"same\",\n",
        "                                 activation=tf.nn.relu)\n",
        "            \n",
        "        pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2, 2], strides=2)  # convolution stride\n",
        "        conv2 = tf.layers.conv2d(\n",
        "                                  inputs=pool1,\n",
        "                                  filters=32, # number of filters\n",
        "                                  kernel_size=[5, 5],\n",
        "                                  padding=\"same\",\n",
        "                                  activation=tf.nn.relu)\n",
        "                                 \n",
        "        pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
        "                                        pool_size=[2, 2],\n",
        "                                        strides=2)  # convolution stride\n",
        "                                        \n",
        "        conv3 = tf.layers.conv2d(\n",
        "                                 inputs=pool2,\n",
        "                                 filters=32, # number of filters\n",
        "                                  kernel_size=[5, 5],\n",
        "                                  padding=\"same\",\n",
        "                                  activation=tf.nn.relu)\n",
        "                                        \n",
        "        pool3 = tf.layers.max_pooling2d(inputs=conv3,\n",
        "                                        pool_size=[2, 2],\n",
        "                                        strides=2)\n",
        "        \n",
        "        conv4 = tf.layers.conv2d(\n",
        "                                 inputs=pool3,\n",
        "                                 filters=32, # number of filters\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 padding=\"same\",\n",
        "                                 activation=tf.nn.relu)\n",
        "            \n",
        "        pool4 = tf.layers.max_pooling2d(inputs=conv4,\n",
        "                                        pool_size=[2, 2],\n",
        "                                        strides=2)\n",
        "                                 \n",
        "        pool_flat = tf.contrib.layers.flatten(pool4, scope='pool2flat')\n",
        "        dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
        "        logits = tf.layers.dense(inputs=dense, units=num_of_classes)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm_WCEJ2Et1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_classification_loss(cnn,model_function):\n",
        "    with tf.Graph().as_default() as g:\n",
        "        with tf.device(\"/cpu:0\"):  # use gpu:0 if on GPU\n",
        "            x_ = tf.placeholder(tf.float32, [None, cnn.image_size, cnn.image_size,1],name='x')\n",
        "            y_ = tf.placeholder(tf.int32, [None],name='y')\n",
        "            y_logits = model_function(x_,cnn.num_of_classes)\n",
        "            \n",
        "            y_dict = dict(labels=y_, logits=y_logits)\n",
        "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n",
        "            cross_entropy_loss = tf.reduce_mean(losses)\n",
        "            trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "            train_op = trainer.minimize(cross_entropy_loss)\n",
        "            y_pred = tf.argmax(tf.nn.softmax(y_logits), axis=1)\n",
        "            correct_prediction = tf.equal(tf.cast(y_pred, tf.int32), y_)\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    model_dict = {'graph': g, 'inputs': [x_, y_], 'train_op': train_op,\n",
        "                               'accuracy': accuracy, 'loss': cross_entropy_loss}\n",
        "\n",
        "    return model_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960J-rWHExvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(cnn,x,y,i):\n",
        "    start=i*cnn.batch_size\n",
        "    end=start+cnn.batch_size\n",
        "    if (end>x.shape[0]):\n",
        "        end=x.shape[0]\n",
        "    x_batch_data=x[start:end,:,:,:]\n",
        "    y_batch_data=y[start:end]\n",
        "    return x_batch_data,y_batch_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBG5bSErE2Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(cnn,model_dict, x_data,y_data,x_test,y_test ,epoch_n, print_every):\n",
        "    epoch_n=10\n",
        "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
        "        saver = tf.train.Saver()\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        batch_num=int(np.ceil(x_data.shape[0]/cnn.batch_size))\n",
        "        for epoch_i in range(epoch_n):\n",
        "            for iter_i in range(batch_num):\n",
        "                x_placeholder=model_dict['inputs'][0]\n",
        "                y_placeholder=model_dict['inputs'][1]\n",
        "                #train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
        "                [x_batch_data,y_batch_data]=get_data(cnn,x_data,y_data,iter_i)\n",
        "                sess.run(model_dict['train_op'], feed_dict={x_placeholder:x_batch_data,y_placeholder:y_batch_data})\n",
        "\n",
        "                if (iter_i%200==0):\n",
        "                    to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
        "                    loss,accuracy=sess.run(to_compute, feed_dict={x_placeholder:x_test,y_placeholder:y_test})\n",
        "                    print(iter_i,\"/\",batch_num,\"loss:\",loss,\" accuracy:\",accuracy)\n",
        "        saver.save(sess, \"/content/drive/My Drive/BE_project_dataset_and_code/data/model.ckpt\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWGTc35ME7Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(cnn,args):\n",
        "    dir_data='/content/drive/My Drive/BE_project_dataset_and_code/data/'\n",
        "    num_of_classess,dict=create_dic(dir_data)\n",
        "    data_l=np.zeros((1))\n",
        "    data_d=np.zeros((1,cnn.image_size*cnn.image_size))\n",
        "    index=1\n",
        "    for file in sorted(os.listdir(dir_data)):\n",
        "        if file.endswith(\".npy\"):\n",
        "            print(data_l.shape,data_d.shape,\"cur label num!\",index,file)\n",
        "            curr_data=np.load(dir_data+file)\n",
        "            data_size=curr_data.shape\n",
        "            #take only 30 percent of the data\n",
        "            #part_data=int((int(args.draws_per_class)/100)*(data_size[0]))\n",
        "            part_data=int((int(args[1])/100)*(data_size[0]))\n",
        "            curr_data=curr_data[1:part_data,:]\n",
        "            \n",
        "            #change to white background\n",
        "            curr_data=255-curr_data;\n",
        "            data_d=np.concatenate((data_d,curr_data))\n",
        "            data_l=np.concatenate((data_l,np.ones(curr_data.shape[0])*index))\n",
        "            if (index==int(args[2])):\n",
        "                break\n",
        "            index=index+1\n",
        "    data_l=np.expand_dims(data_l,1)\n",
        "    data_all=np.concatenate((data_d,data_l),axis=1)\n",
        "    data_all=np.random.permutation(data_all)\n",
        "\n",
        "    x_data=data_all[:,0:-1]\n",
        "    y_data=data_all[:,-1]\n",
        "    num_img=x_data.shape[0]\n",
        "    data_img=np.reshape(x_data,[num_img,cnn.image_size,cnn.image_size])\n",
        "   \n",
        "    \n",
        "    data_train=data_img[cnn.validate_data:,:,:]\n",
        "    data_train=np.expand_dims(data_train,3)\n",
        "\n",
        "    labels_train=y_data[cnn.validate_data:]\n",
        "    data_test=data_img[:cnn.validate_data:,:,:]\n",
        "    data_test=np.expand_dims(data_test,3)\n",
        "\n",
        "    labels_test=y_data[:cnn.validate_data]\n",
        "\n",
        "    \n",
        "    return data_train,labels_train,data_test,labels_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rri2Acu_E_mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(args):\n",
        "    quick_draw_cnn=cnn()\n",
        "    [x_data,y_data,x_test,y_test]=load_data(quick_draw_cnn,args)\n",
        "\n",
        "    model_dict = apply_classification_loss(quick_draw_cnn,SVHN_net_v0)\n",
        "    #train_model(quick_draw_cnn,model_dict, x_data,y_data,x_test,y_test ,epoch_n=int(args.epoch), print_every=20)\n",
        "    train_model(quick_draw_cnn,model_dict, x_data,y_data,x_test,y_test ,epoch_n=int(args[0]), print_every=20)\n",
        "\n",
        "    #test test data after finishing training\n",
        "    print(\"It's here\")\n",
        "    y_predicted=test.test_cnn(quick_draw_cnn,x_test,y_test)\n",
        "\n",
        "    mistakes=np.nonzero(y_predicted-y_test)\n",
        "    #mistakes is tuple,take the array only\n",
        "    mistakes=mistakes[0]\n",
        "    error_rate=mistakes.shape[0]/y_test.shape[0]\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"Final accuracy is :\",1-error_rate)\n",
        "    print(\"-----------------------------------------------------------------------\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBogQ5TJFVpH",
        "colab_type": "code",
        "outputId": "cd296c08-30d6-4bfe-ffa3-a5a22337850c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-ep', '--epoch', default=10)\n",
        "    parser.add_argument('-dpc', '--draws_per_class', default=30)\n",
        "    parser.add_argument('-class_num', '--class_num', default=30)\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    \"\"\"\n",
        "    args=[10,31,31]\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    #print(\"Train CNN with \" ,args.epoch,\"epochs\",args.class_num,\"classes\",args.draws_per_class,\"percent draws from each class\")\n",
        "    print(\"Train CNN with \" ,args[0],\"epochs\",args[1],\"classes\",args[2],\"percent draws from each class\")\n",
        "    \n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    main(args)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "Train CNN with  10 epochs 31 classes 31 percent draws from each class\n",
            "-----------------------------------------------------------------------\n",
            "(1,) (1, 784) cur label num! 1 ambulance.npy\n",
            "(45881,) (45881, 784) cur label num! 2 apple.npy\n",
            "(90743,) (90743, 784) cur label num! 3 axe.npy\n",
            "(129219,) (129219, 784) cur label num! 4 basketball.npy\n",
            "(170693,) (170693, 784) cur label num! 5 bicycle.npy\n",
            "(209915,) (209915, 784) cur label num! 6 boomerang.npy\n",
            "(254145,) (254145, 784) cur label num! 7 butterfly.npy\n",
            "(290723,) (290723, 784) cur label num! 8 car.npy\n",
            "(347378,) (347378, 784) cur label num! 9 carrot.npy\n",
            "(388439,) (388439, 784) cur label num! 10 cat.npy\n",
            "(426630,) (426630, 784) cur label num! 11 clock.npy\n",
            "(463995,) (463995, 784) cur label num! 12 cookie.npy\n",
            "(504713,) (504713, 784) cur label num! 13 cup.npy\n",
            "(545235,) (545235, 784) cur label num! 14 donut.npy\n",
            "(588866,) (588866, 784) cur label num! 15 envelope.npy\n",
            "(630672,) (630672, 784) cur label num! 16 flower.npy\n",
            "(675564,) (675564, 784) cur label num! 17 hammer.npy\n",
            "(712456,) (712456, 784) cur label num! 18 key.npy\n",
            "(762354,) (762354, 784) cur label num! 19 knife.npy\n",
            "(815876,) (815876, 784) cur label num! 20 lightning.npy\n",
            "(862858,) (862858, 784) cur label num! 21 pencil.npy\n",
            "(900677,) (900677, 784) cur label num! 22 pizza.npy\n",
            "(941091,) (941091, 784) cur label num! 23 rainbow.npy\n",
            "(980411,) (980411, 784) cur label num! 24 snake.npy\n",
            "(1018314,) (1018314, 784) cur label num! 25 spider.npy\n",
            "(1083241,) (1083241, 784) cur label num! 26 star.npy\n",
            "(1125901,) (1125901, 784) cur label num! 27 tractor.npy\n",
            "(1162069,) (1162069, 784) cur label num! 28 tree.npy\n",
            "(1206931,) (1206931, 784) cur label num! 29 whale.npy\n",
            "(1243045,) (1243045, 784) cur label num! 30 windmill.npy\n",
            "WARNING:tensorflow:From <ipython-input-11-b0f52411c58f>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-11-b0f52411c58f>:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-11-b0f52411c58f>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 30 which is outside the valid range of [0, 30).  Label values: 4 7 27 26 27 22 9 4 8 21 16 22 2 24 11 25 30 14 9 21 18 14 6 25 27 17 22 11 21 5 18 30 21 29 25 22 4 4 14 21 4 14 3 7 21 15 2 5 1 3 20 14 18 18 10 12 26 6 6 12 4 18 18 23 10 15 5 15 2 4 19 9 4 30 8 4 26 19 28 25 25 1 14 1 22 25 25 9 11 14 21 12 29 12 8 25 26 1 14 7 16 25 5 19 5 18 1 25 6 8 25 3 10 13 30 29 8 3 12 4 10 4 22 13 24 19 8 3\n\t [[{{node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2ac528a3bbae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-8727badbf580>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_classification_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquick_draw_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSVHN_net_v0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#train_model(quick_draw_cnn,model_dict, x_data,y_data,x_test,y_test ,epoch_n=int(args.epoch), print_every=20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquick_draw_cnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepoch_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#test test data after finishing training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-0ac99c79e6f8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(cnn, model_dict, x_data, y_data, x_test, y_test, epoch_n, print_every)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;31m#train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mx_batch_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_batch_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_batch_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter_i\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 30 which is outside the valid range of [0, 30).  Label values: 4 7 27 26 27 22 9 4 8 21 16 22 2 24 11 25 30 14 9 21 18 14 6 25 27 17 22 11 21 5 18 30 21 29 25 22 4 4 14 21 4 14 3 7 21 15 2 5 1 3 20 14 18 18 10 12 26 6 6 12 4 18 18 23 10 15 5 15 2 4 19 9 4 30 8 4 26 19 28 25 25 1 14 1 22 25 25 9 11 14 21 12 29 12 8 25 26 1 14 7 16 25 5 19 5 18 1 25 6 8 25 3 10 13 30 29 8 3 12 4 10 4 22 13 24 19 8 3\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-2ac528a3bbae>\", line 17, in <module>\n    main(args)\n  File \"<ipython-input-16-8727badbf580>\", line 5, in main\n    model_dict = apply_classification_loss(quick_draw_cnn,SVHN_net_v0)\n  File \"<ipython-input-12-8b1e5f072887>\", line 9, in apply_classification_loss\n    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_ops.py\", line 3397, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/gen_nn_ops.py\", line 11838, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHX1Gc77NeRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}