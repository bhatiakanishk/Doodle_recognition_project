{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXUo4GC1Q2jViBoeVe5/hx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitgupta1998/Doodle_recogn_BEproject/blob/master/train_changes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0ECv9kjDwO6",
        "colab_type": "code",
        "outputId": "37291a2f-d8c4-4b19-8080-10a0ebd1e616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "import cv2\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import test as test #file name, look how to import colab file\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CId4TMBERyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir_data='/content/drive/My Drive/BE_project_dataset_and_code/data/'    \n",
        "def create_dic(dir_data):\n",
        "    dict={}\n",
        "    i=0\n",
        "    for file in sorted(os.listdir(dir_data)):\n",
        "        if file.endswith(\".npy\"):\n",
        "            str=file.split(\".\")\n",
        "            dict[i]=str[0]\n",
        "            i=i+1\n",
        "    return i,dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evd5k9cOEShs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class cnn:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 128\n",
        "        self.dir_data='/content/drive/My Drive/BE_project_dataset_and_code/data/'\n",
        "        self.num_of_classes,self.dict =create_dic(self.dir_data)\n",
        "        self.image_size = 28\n",
        "        self.validate_data = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM62gAtbElCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SVHN_net_v0(x_,num_of_classes):\n",
        "    with tf.variable_scope(\"CNN\"):\n",
        "        conv1 = tf.layers.conv2d(\n",
        "                                 inputs=x_,\n",
        "                                 filters=32,  # number of filters\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 padding=\"same\",\n",
        "                                 activation=tf.nn.relu)\n",
        "            \n",
        "        pool1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2, 2], strides=2)  # convolution stride\n",
        "        conv2 = tf.layers.conv2d(\n",
        "                                  inputs=pool1,\n",
        "                                  filters=32, # number of filters\n",
        "                                  kernel_size=[5, 5],\n",
        "                                  padding=\"same\",\n",
        "                                  activation=tf.nn.relu)\n",
        "                                 \n",
        "        pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
        "                                        pool_size=[2, 2],\n",
        "                                        strides=2)  # convolution stride\n",
        "                                        \n",
        "        conv3 = tf.layers.conv2d(\n",
        "                                 inputs=pool2,\n",
        "                                 filters=32, # number of filters\n",
        "                                  kernel_size=[5, 5],\n",
        "                                  padding=\"same\",\n",
        "                                  activation=tf.nn.relu)\n",
        "                                        \n",
        "        pool3 = tf.layers.max_pooling2d(inputs=conv3,\n",
        "                                        pool_size=[2, 2],\n",
        "                                        strides=2)\n",
        "        \n",
        "        conv4 = tf.layers.conv2d(\n",
        "                                 inputs=pool3,\n",
        "                                 filters=32, # number of filters\n",
        "                                 kernel_size=[5, 5],\n",
        "                                 padding=\"same\",\n",
        "                                 activation=tf.nn.relu)\n",
        "            \n",
        "        pool4 = tf.layers.max_pooling2d(inputs=conv4,\n",
        "                                        pool_size=[2, 2],\n",
        "                                        strides=2)\n",
        "                                 \n",
        "        pool_flat = tf.contrib.layers.flatten(pool4, scope='pool2flat')\n",
        "        dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
        "        logits = tf.layers.dense(inputs=dense, units=num_of_classes)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm_WCEJ2Et1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_classification_loss(cnn,model_function):\n",
        "    with tf.Graph().as_default() as g:\n",
        "        with tf.device(\"/cpu:0\"):  # use gpu:0 if on GPU\n",
        "            x_ = tf.placeholder(tf.float32, [None, cnn.image_size, cnn.image_size,1],name='x')\n",
        "            y_ = tf.placeholder(tf.int32, [None],name='y')\n",
        "            y_logits = model_function(x_,cnn.num_of_classes)\n",
        "            \n",
        "            y_dict = dict(labels=y_, logits=y_logits)\n",
        "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n",
        "            cross_entropy_loss = tf.reduce_mean(losses)\n",
        "            trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "            train_op = trainer.minimize(cross_entropy_loss)\n",
        "            y_pred = tf.argmax(tf.nn.softmax(y_logits), axis=1)\n",
        "            correct_prediction = tf.equal(tf.cast(y_pred, tf.int32), y_)\n",
        "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    model_dict = {'graph': g, 'inputs': [x_, y_], 'train_op': train_op,\n",
        "                               'accuracy': accuracy, 'loss': cross_entropy_loss}\n",
        "\n",
        "    return model_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960J-rWHExvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(cnn,x,y,i):\n",
        "    start=i*cnn.batch_size\n",
        "    end=start+cnn.batch_size\n",
        "    if (end>x.shape[0]):\n",
        "        end=x.shape[0]\n",
        "    x_batch_data=x[start:end,:,:,:]\n",
        "    y_batch_data=y[start:end]\n",
        "    return x_batch_data,y_batch_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBG5bSErE2Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(cnn,model_dict, x_data,y_data,x_test,y_test ,epoch_n, print_every):\n",
        "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
        "        saver = tf.train.Saver()\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        batch_num=int(np.ceil(x_data.shape[0]/cnn.batch_size))\n",
        "        for epoch_i in range(epoch_n):\n",
        "            for iter_i in range(batch_num):\n",
        "                x_placeholder=model_dict['inputs'][0]\n",
        "                y_placeholder=model_dict['inputs'][1]\n",
        "                #train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
        "                [x_batch_data,y_batch_data]=get_data(cnn,x_data,y_data,iter_i)\n",
        "                sess.run(model_dict['train_op'], feed_dict={x_placeholder:x_batch_data,y_placeholder:y_batch_data})\n",
        "\n",
        "                if (iter_i%200==0):\n",
        "                    to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
        "                    loss,accuracy=sess.run(to_compute, feed_dict={x_placeholder:x_test,y_placeholder:y_test})\n",
        "                    print(iter_i,\"/\",batch_num,\"loss:\",loss,\" accuracy:\",accuracy)\n",
        "        saver.save(sess, \"./saved_sess/model.ckpt\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWGTc35ME7Bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(cnn,args):\n",
        "    dir_data='../data/'\n",
        "    num_of_classess,dict=create_dic(dir_data)\n",
        "    data_l=np.zeros((1))\n",
        "    data_d=np.zeros((1,cnn.image_size*cnn.image_size))\n",
        "    index=1\n",
        "    for file in sorted(os.listdir(dir_data)):\n",
        "        if file.endswith(\".npy\"):\n",
        "            print(data_l.shape,data_d.shape,\"cur label num!\",index,file)\n",
        "            curr_data=np.load(dir_data+file)\n",
        "            data_size=curr_data.shape\n",
        "            #take only 30 percent of the data\n",
        "            part_data=int((int(args.draws_per_class)/100)*(data_size[0]))\n",
        "            curr_data=curr_data[1:part_data,:]\n",
        "            \n",
        "            #change to white background\n",
        "            curr_data=255-curr_data;\n",
        "            data_d=np.concatenate((data_d,curr_data))\n",
        "            data_l=np.concatenate((data_l,np.ones(curr_data.shape[0])*index))\n",
        "            if (index==int(args.class_num)):\n",
        "                break\n",
        "            index=index+1\n",
        "    data_l=np.expand_dims(data_l,1)\n",
        "    data_all=np.concatenate((data_d,data_l),axis=1)\n",
        "    data_all=np.random.permutation(data_all)\n",
        "\n",
        "    x_data=data_all[:,0:-1]\n",
        "    y_data=data_all[:,-1]\n",
        "    num_img=x_data.shape[0]\n",
        "    data_img=np.reshape(x_data,[num_img,cnn.image_size,cnn.image_size])\n",
        "   \n",
        "    \n",
        "    data_train=data_img[cnn.validate_data:,:,:]\n",
        "    data_train=np.expand_dims(data_train,3)\n",
        "\n",
        "    labels_train=y_data[cnn.validate_data:]\n",
        "    data_test=data_img[:cnn.validate_data:,:,:]\n",
        "    data_test=np.expand_dims(data_test,3)\n",
        "\n",
        "    labels_test=y_data[:cnn.validate_data]\n",
        "\n",
        "    \n",
        "    return data_train,labels_train,data_test,labels_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rri2Acu_E_mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(args):\n",
        "    quick_draw_cnn=cnn()\n",
        "    [x_data,y_data,x_test,y_test]=load_data(quick_draw_cnn,args)\n",
        "\n",
        "    model_dict = apply_classification_loss(quick_draw_cnn,SVHN_net_v0)\n",
        "    train_model(quick_draw_cnn,model_dict, x_data,y_data,x_test,y_test ,epoch_n=int(args.epoch), print_every=20)\n",
        "\n",
        "    #test test data after finishing training\n",
        "    y_predicted=test.test_cnn(quick_draw_cnn,x_test,y_test)\n",
        "\n",
        "    mistakes=np.nonzero(y_predicted-y_test)\n",
        "    #mistakes is tuple,take the array only\n",
        "    mistakes=mistakes[0]\n",
        "    error_rate=mistakes.shape[0]/y_test.shape[0]\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"Final accuracy is :\",1-error_rate)\n",
        "    print(\"-----------------------------------------------------------------------\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBogQ5TJFVpH",
        "colab_type": "code",
        "outputId": "6d904550-5fc2-459f-981b-cc41d42ffe97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-ep', '--epoch', default=10)\n",
        "    parser.add_argument('-dpc', '--draws_per_class', default=30)\n",
        "    parser.add_argument('-class_num', '--class_num', default=30)\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    \"\"\"\n",
        "    x=10\n",
        "    y=30\n",
        "    z=30\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    print(\"Train CNN with \" ,args.epoch,\"epochs\",args.class_num,\"classes\",args.draws_per_class,\"percent draws from each class\")\n",
        "    print(\"-----------------------------------------------------------------------\")\n",
        "    #main(args)\n",
        "    main(x,y,z)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-ep EPOCH] [-dpc DRAWS_PER_CLASS]\n",
            "                             [-class_num CLASS_NUM]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-5650cbf2-0a02-4c4b-b3b3-dc3914165af9.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v6DWiBxFX57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "951d0eaa-b43f-47ae-8ad6-6255bdfd9ad9"
      },
      "source": [
        "%tb"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-146cbbfa11a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-dpc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--draws_per_class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-class_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--class_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-----------------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train CNN with \"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"classes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraws_per_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"percent draws from each class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unrecognized arguments: %s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1746\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1747\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2400\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2402\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcUvfw4HYZh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}